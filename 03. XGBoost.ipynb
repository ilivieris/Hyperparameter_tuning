{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "# Basic libraries\n",
    "import os\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "# Optuna library\n",
    "import optuna\n",
    "# XGBoost\n",
    "import xgboost\n",
    "# User libraries\n",
    "from utils.Logger import *\n",
    "from utils.utils import *\n",
    "from utils.mlflow_logging import MLflow_log_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Optuna trials \n",
    "n_trials = 5\n",
    "# Seed\n",
    "seed = 42 \n",
    "# Create logger\n",
    "VERBOSE = True \n",
    "# Number of splits for Stratified Cross-Validation\n",
    "n_splits = 10\n",
    "# Hold-out percentage\n",
    "test_size = 0.2\n",
    "\n",
    "# Create temp directory for storing output figures\n",
    "if not os.path.isdir('Performance'): os.mkdir('Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate logger\n",
    "if VERBOSE:\n",
    "    logger = init_logger(log_file = 'logs.log') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/dataset.csv').dropna()\n",
    "\n",
    "if VERBOSE:\n",
    "    logger.info(f'Training data were loaded')\n",
    "    logger.info(f'Number of instances:  {df.shape[0]}')\n",
    "    logger.info(f'Number of features:   {df.shape[1]}')\n",
    "\n",
    "df['Class'].hist(figsize=(4, 2))\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data (training/holdout set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=test_size, stratify=df['Class'], random_state=seed)\n",
    "\n",
    "# Get X & y\n",
    "trainX = df_train.iloc[:, :-1].values\n",
    "trainY = df_train.iloc[:,  -1].values.astype('int')\n",
    "\n",
    "testX = df_test.iloc[:, :-1].values\n",
    "testY = df_test.iloc[:,  -1].values.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate mlflow server\n",
    "# Command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 127.0.0.1 --port 5000\n",
    "# \n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"Experiment1 XGBoost\")\n",
    "\n",
    "if VERBOSE:\n",
    "    logger.info('MLFlow server is connected')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float: \n",
    "    # Logger\n",
    "    if VERBOSE:\n",
    "        logger.info(f'Trail: {trial.number} started [{trial.datetime_start}]')\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'n_estimators'      : trial.suggest_categorical('n_estimators', [50, 100, 200]),\n",
    "        'learning_rate'     : trial.suggest_categorical('learning_rate' , [1e-3, 1e-4, 1e-5]),\n",
    "        'max_depth'         : trial.suggest_int('max_depth', 3, 5),\n",
    "        'reg_alpha'         : trial.suggest_categorical('reg_alpha', [10, 20, 30]),\n",
    "        'reg_lambda'        : 1.0, #trial.suggest_loguniform('reg_lambda', 0, 1),\n",
    "        'gamma'             : 1, #trial.suggest_loguniform('gamma', 1 , 9),\n",
    "        'min_child_weight'  : 2, #trial.suggest_int('min_child_weight', 2, 4),\n",
    "        'max_leaves'        : 2, #trial.suggest_int('max_leaves', 2, 5),\n",
    "    }\n",
    "\n",
    "\n",
    "    # Setup model\n",
    "    model = xgboost.XGBClassifier(objective           = 'multi:softmax',  \n",
    "                                    n_jobs              = -1,                                   \n",
    "                                    validate_parameters = True, \n",
    "                                    verbosity           = 1,\n",
    "                                    tree_method         = 'hist',\n",
    "                                    **params)\n",
    "    \n",
    "    # Cross-Validation\n",
    "    train_CV_results, test_CV_results, CM_cv = cross_validation(model=model, X=trainX, Y=trainY, n_splits=n_splits, seed=seed, VERBOSE=VERBOSE)\n",
    "\n",
    "    # Single-run \n",
    "    model, train_results, test_results, CM, predictions = single_run(model=model, trainX=trainX, trainY=trainY, testX=testX, testY=testY, VERBOSE=VERBOSE)\n",
    "\n",
    "         \n",
    "    if VERBOSE:\n",
    "        logger.info(f'Trail: {trial.number} completed')\n",
    "\n",
    "    # Include model signature\n",
    "    signature = mlflow.models.infer_signature(testX, predictions)\n",
    "    # Log performance to MLflow \n",
    "    MLflow_log_performance(trial.number, model, \n",
    "                           train_CV_results, test_CV_results, CM_cv, \n",
    "                           train_results, test_results, CM,\n",
    "                           signature, params)\n",
    "\n",
    "    \n",
    "    if VERBOSE:\n",
    "        logger.info(f'Trail: {trial.number} completed')\n",
    "\n",
    "\n",
    "    return np.mean(test_CV_results['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed = seed),\n",
    "                           )\n",
    "\n",
    "study.optimize(func=objective, \n",
    "               n_trials=n_trials, \n",
    "               n_jobs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temp directory\n",
    "import shutil\n",
    "shutil.rmtree('Performance')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the learning curves of the trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of hyperparameter relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study, params=[params for params in study.best_params])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, \n",
    "                                            target      = lambda t: t.duration.total_seconds(), \n",
    "                                            target_name = \"duration\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] Optimized hyperparameters\\n')\n",
    "for (parameter,value) in study.best_params.items():\n",
    "    if ( isinstance(value, float) ):\n",
    "        print(' >%25s: %.3f' % (parameter,value))\n",
    "    else:\n",
    "        print(' >%25s: %s' % (parameter,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
